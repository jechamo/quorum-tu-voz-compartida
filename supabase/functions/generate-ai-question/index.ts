import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

serve(async (req) => {
  if (req.method === "OPTIONS") return new Response("ok", { headers: corsHeaders });

  try {
    const { topic, entity, module, mode, entitiesList, model } = await req.json();
    const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");
    const TAVILY_API_KEY = Deno.env.get("TAVILY_API_KEY");

    if (!OPENAI_API_KEY || !TAVILY_API_KEY) throw new Error("Faltan API Keys");

    // 1. ESTRATEGIA DE B√öSQUEDA INTELIGENTE
    let contextNews = "";

    // Definimos dominios seg√∫n el m√≥dulo
    const domains =
      module === "futbol"
        ? ["marca.com", "as.com", "mundodeportivo.com", "sport.es", "relevo.com"]
        : ["elpais.com", "elmundo.es", "elconfidencial.com", "okdiario.com", "eldiario.es", "abc.es", "elespanol.com"];

    // Construimos la Query principal
    let primaryQuery = "";
    if (mode === "batch") {
      primaryQuery = `Noticias √∫ltima hora pol√©mica ${module} Espa√±a actualidad`;
    } else {
      // Truco: Quitamos la palabra "pol√©mica" de la b√∫squeda estricta para encontrar m√°s resultados,
      // la IA ya buscar√° la pol√©mica dentro de la noticia.
      primaryQuery = `${entity} ${module} Espa√±a noticias √∫ltima hora ${topic || ""}`;
    }

    console.log(`üîé Buscando: "${primaryQuery}"`);

    // Hacemos la b√∫squeda
    const searchResponse = await fetch("https://api.tavily.com/search", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        api_key: TAVILY_API_KEY,
        query: primaryQuery,
        search_depth: "news",
        include_domains: domains,
        max_results: mode === "batch" ? 7 : 5, // M√°s resultados para tener donde elegir
      }),
    });

    const searchData = await searchResponse.json();

    if (searchData.results && searchData.results.length > 0) {
      contextNews = searchData.results.map((r: any) => `- ${r.title}: ${r.content}`).join("\n");
      console.log(`‚úÖ Encontradas ${searchData.results.length} noticias.`);
    } else {
      console.log("‚ö†Ô∏è No se encontraron noticias espec√≠ficas. Usando contexto general.");
      contextNews =
        "No hay noticias de √∫ltima hora espec√≠ficas. Usa tu conocimiento general sobre pol√©micas recientes y recurrentes de esta entidad.";
    }

    // 2. PROMPT "SALSERO" REFORZADO
    const systemPrompt = `
      Eres el redactor jefe m√°s pol√©mico de Espa√±a.
      
      TU MISI√ìN: Generar debate social intenso.
      
      FUENTES (√öSALAS SI PUEDES, SI NO, TIRA DE HEMEROTECA RECIENTE):
      ${contextNews}

      OBJETIVO:
      ${
        mode === "batch"
          ? `Genera una bater√≠a de preguntas:
           1. OBLIGATORIO: Una pregunta GENERAL sobre el tema m√°s caliente del momento en ${module}.
           2. OPCIONAL: Preguntas espec√≠ficas para: [${entitiesList ? entitiesList.join(", ") : ""}].
           IMPORTANTE: Intenta sacar al menos 3 preguntas en total. Si no hay noticia de hoy para un partido/equipo, busca su pol√©mica m√°s reciente (siempre hay algo).`
          : `Genera una encuesta sobre: ${entity}. Si no hay noticia de hoy, usa su pol√©mica recurrente m√°s famosa.`
      }

      REGLAS DE ORO:
      1. PREGUNTAS CORTAS Y DIRECTAS: "¬øEs culpable...?", "¬øDebe dimitir...?", "¬øAcierto o error?".
      2. OPCIONES CON ACTITUD: [Indignado], [Defensor a muerte], [Esc√©ptico], [Indiferente].
      3. PROHIBIDO: Preguntas tibias como "¬øQu√© opinas de la situaci√≥n?".
      
      FORMATO JSON:
      {
        "results": [
          { "question": "¬ø...?", "options": ["...", "...", "...", "..."], "target_entity": "Nombre" }
        ]
      }
    `;

    const aiModel = model || "gpt-4o-mini";
    const requestBody: any = {
      model: aiModel,
      messages: [{ role: "system", content: systemPrompt }],
      response_format: { type: "json_object" },
    };

    if (aiModel.includes("gpt-5") || aiModel.startsWith("o1")) {
      requestBody.max_completion_tokens = 4000;
    } else {
      requestBody.max_tokens = 4000;
      requestBody.temperature = 0.9; // Subimos la temperatura para que sea m√°s creativo si no hay noticias
    }

    const openAiResponse = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify(requestBody),
    });

    if (!openAiResponse.ok) {
      const err = await openAiResponse.text();
      throw new Error(`OpenAI Error: ${err}`);
    }

    const aiData = await openAiResponse.json();
    const result = JSON.parse(aiData.choices[0].message.content);

    return new Response(JSON.stringify(result), {
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  } catch (error: any) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error("Error:", errorMessage);
    return new Response(JSON.stringify({ error: errorMessage }), {
      status: 500,
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  }
});
